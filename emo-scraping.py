# ä¸€åº¦ã ã‘å®Ÿè¡Œ
# pip install transformers sentencepiece fugashi unidic-lite torch pandas plotly requests beautifulsoup4 lxml

import streamlit as st
import torch
import pandas as pd
import requests
from bs4 import BeautifulSoup
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    T5Tokenizer,
    AutoModelForSeq2SeqLM,
)
import plotly.express as px

# â”€â”€â”€ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_models():
    # P/N æ„Ÿæƒ…åˆ†æ
    s_name   = "jarvisx17/japanese-sentiment-analysis"
    tok_s    = AutoTokenizer.from_pretrained(s_name)
    model_s  = AutoModelForSequenceClassification.from_pretrained(s_name)
    # è¦ç´„ãƒ¢ãƒ‡ãƒ«ï¼ˆlegacy=False æŒ‡å®šï¼‰
    t5_name  = "Zolyer/ja-t5-base-summary"
    tok_t5   = T5Tokenizer.from_pretrained(t5_name, use_fast=False, legacy=False)
    model_t5 = AutoModelForSeq2SeqLM.from_pretrained(t5_name)
    # 8è»¸æ„Ÿæƒ…ï¼ˆWRIME fine-tuneï¼‰
    e_name   = "patrickramos/bert-base-japanese-v2-wrime-fine-tune"
    tok_e    = AutoTokenizer.from_pretrained(e_name)
    model_e  = AutoModelForSequenceClassification.from_pretrained(e_name)
    # æ ¡æ­£ç”¨ã«ã‚‚åŒã˜ T5ï¼ˆlegacy=Falseï¼‰
    cor_tok   = tok_t5
    cor_model = model_t5
    return (tok_s, model_s), (tok_t5, model_t5), (tok_e, model_e), (cor_tok, cor_model)

(sent_tok, sent_model), (sum_tok, sum_model), (emo_tok, emo_model), (cor_tok, cor_model) = load_models()

# â”€â”€â”€ URLâ†’æœ¬æ–‡æŠ½å‡º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_text(url: str) -> str:
    r = requests.get(url, timeout=10)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "lxml")
    return "\n".join(p.get_text().strip() for p in soup.find_all("p") if p.get_text().strip())

# â”€â”€â”€ æ„Ÿæƒ…åˆ†æ (P/N) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_sentiment(text: str):
    # å¿…ãš max_length=512 ã§ truncate & pad
    inputs = sent_tok(
        text,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=512
    )
    with torch.no_grad():
        logits = sent_model(**inputs).logits
    probs = torch.softmax(logits, dim=1)[0]
    score, idx = torch.max(probs, dim=0)
    label = sent_model.config.id2label[idx.item()]
    return label, score.item()

# â”€â”€â”€ Plutchik ã® 8 æ„Ÿæƒ…åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_plutchik8(text: str):
    inputs = emo_tok(
        text,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=512
    )
    with torch.no_grad():
        raw = emo_model(**inputs).logits[0][:8].tolist()
    labels = ["æ­“å–œ", "æ‚²å“€", "æœŸå¾…", "é©šæ„•", "æ†¤æ€’", "ææ€–", "å«Œæ‚ª", "ä¿¡é ¼"]
    return {lab: round(val, 3) for lab, val in zip(labels, raw)}

# â”€â”€â”€ è¦ç´„ (è‡ªå‹•ãƒˆãƒ¼ã‚¯ãƒ³é•·è¨­å®š) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def summarize(text: str) -> str:
    if len(text) < 20:
        return text

    prefixed = "è¦ç´„: " + text

    # â‘  å…¥åŠ›é•·è¨ˆæ¸¬ï¼ˆtruncate ã ã‘ï¼‰
    len_inputs = sum_tok(
        prefixed,
        return_tensors="pt",
        truncation=True,
        max_length=512
    )
    token_len = len_inputs["input_ids"].shape[1]

    # â‘¡ æœ¬ç•ªãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºï¼ˆ512 å›ºå®šã§ pad & truncateï¼‰
    inputs = sum_tok(
        prefixed,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=512
    )

    # â‘¢ max/min é•·ã‚’è‡ªå‹•è¨­å®š
    max_len = min(int(token_len * 0.7) + 10, 200)
    min_len = max(int(token_len * 0.3), 10)
    if min_len > max_len:
        min_len = max_len

    summary_ids = sum_model.generate(
        **inputs,
        max_length=max_len,
        min_length=min_len,
        num_beams=6,
        early_stopping=True,
        length_penalty=1.0,
        no_repeat_ngram_size=2,
        repetition_penalty=1.2,
    )
    return sum_tok.decode(summary_ids[0], skip_special_tokens=True)

# â”€â”€â”€ æ ¡æ­£ (Grammar Correction) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def correct_text(text: str) -> str:
    pref = "æ ¡æ­£: " + text

    inputs = cor_tok(
        pref,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=512
    )
    max_len = min(inputs["input_ids"].shape[1] + 50, 512)
    with torch.no_grad():
        ids = cor_model.generate(
            **inputs,
            max_length=max_len,
            num_beams=4,
            early_stopping=True,
        )
    return cor_tok.decode(ids[0], skip_special_tokens=True)

# â”€â”€â”€ Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("<h2 style='font-size:22px;'>ğŸ“˜ æ—¥æœ¬èªãƒã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª</h2>", unsafe_allow_html=True)
st.write("URL ã¾ãŸã¯ ãƒ†ã‚­ã‚¹ãƒˆ ã‚’å…¥åŠ›ã—ã€ã€Œåˆ†æå®Ÿè¡Œã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

raw = st.text_input("ğŸ”¹ URL or ãƒ†ã‚­ã‚¹ãƒˆ", "")
if st.button("åˆ†æå®Ÿè¡Œ") and raw:
    if raw.startswith("http"):
        with st.spinner("Webãƒšãƒ¼ã‚¸ã‚’å–å¾—ä¸­â€¦"):
            try:
                text = fetch_text(raw)
                st.expander("æœ¬æ–‡ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼").write(text)
            except Exception as e:
                st.error(f"å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                st.stop()
    else:
        text = raw

    with st.spinner("åˆ†æä¸­â€¦"):
        label             = analyze_sentiment(text)[0]
        score             = analyze_sentiment(text)[1]
        plutchik8         = analyze_plutchik8(text)
        summary           = summarize(text)
        corrected_summary = correct_text(summary)

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ 8è»¸ã‚’è¡¨ç¤º
    col1, col2 = st.columns([1, 2])
    with col1:
        df = (
            pd.DataFrame.from_dict(plutchik8, orient="index", columns=["score"])
              .sort_values("score", ascending=False)
              .reset_index()
              .rename(columns={"index": "æ„Ÿæƒ…"})
        )
        height = (2 + len(df)) * 60
        fig = px.bar(
            df, x="æ„Ÿæƒ…", y="score",
            title="8è»¸ Plutchik æ„Ÿæƒ…åˆ†æ",
            labels={"score": "å¼·åº¦"},
            height=height
        )
        fig.update_layout(xaxis={'categoryorder':'total descending'},
                          font_family="Meiryo")
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.subheader("ğŸ§  æ„Ÿæƒ…åˆ†æçµæœ (P/N)")
        st.write(f"ãƒ©ãƒ™ãƒ«: **{label}**  ï¼  ã‚¹ã‚³ã‚¢: **{score:.4f}**")
        st.subheader("ğŸ”· 8è»¸ Plutchik æ„Ÿæƒ…çµæœ")
        st.table(plutchik8)
        st.subheader("ğŸ“ è¦ç´„çµæœ (æ ¡æ­£æ¸ˆ)")
        st.write(corrected_summary)
